{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience\n",
    "from torch_geometric.data import Data, download_url\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "gds = GraphDataScience(\"bolt://localhost:7687\", auth=('neo4j', 'neo4jneo4j'), database=\"fb15k-237\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/FB15k-237/train.txt\n",
      "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/FB15k-237/valid.txt\n",
      "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/FB15k-237/test.txt\n"
     ]
    }
   ],
   "source": [
    "url = ('https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/FB15k-237')\n",
    "raw_file_names = ['train.txt', 'valid.txt', 'test.txt']\n",
    "raw_dir = './data_from_url'\n",
    "for filename in raw_file_names:\n",
    "    download_url(f'{url}/{filename}', raw_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def process():\n",
    "    data_list_, node_dict_, rel_dict_ = [], {}, {}\n",
    "    for file_name in raw_file_names:\n",
    "        file_name_path = raw_dir + '/' + file_name\n",
    "        with open(file_name_path, 'r') as f:\n",
    "            data = [x.split('\\t') for x in f.read().split('\\n')[:-1]]\n",
    "\n",
    "        edge_index = torch.empty((2, len(data)), dtype=torch.long)\n",
    "        edge_type = torch.empty(len(data), dtype=torch.long)\n",
    "        for i, (src, rel, dst) in enumerate(data):\n",
    "            if src not in node_dict_:\n",
    "                node_dict_[src] = len(node_dict_)\n",
    "            if dst not in node_dict_:\n",
    "                node_dict_[dst] = len(node_dict_)\n",
    "            if rel not in rel_dict_:\n",
    "                rel_dict_[rel] = len(rel_dict_)\n",
    "\n",
    "            edge_index[0, i] = node_dict_[src]\n",
    "            edge_index[1, i] = node_dict_[dst]\n",
    "            edge_type[i] = rel_dict_[rel]\n",
    "\n",
    "        data = Data(edge_index=edge_index, edge_type=edge_type)\n",
    "        data_list_.append(data)\n",
    "\n",
    "    for data in data_list_:\n",
    "        data.num_nodes = len(node_dict_)\n",
    "\n",
    "    return data_list_, node_dict_, rel_dict_\n",
    "\n",
    "data_list, node_dict, rel_dict = process()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=4, name='entity_id', type='UNIQUENESS', schema=(:Entity {id}), ownedIndex=3 )'.}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mClientError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mgds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_cypher\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCREATE CONSTRAINT entity_id FOR (e:Entity) REQUIRE e.id IS UNIQUE\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/src-olga-fork/graph-data-science-client/graphdatascience/graph_data_science.py:234\u001B[0m, in \u001B[0;36mGraphDataScience.run_cypher\u001B[0;34m(self, query, params, database)\u001B[0m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_query_runner, ArrowQueryRunner):\n\u001B[1;32m    232\u001B[0m     qr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_query_runner\u001B[38;5;241m.\u001B[39mfallback_query_runner()\n\u001B[0;32m--> 234\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mqr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatabase\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/src-olga-fork/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:61\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.run_query\u001B[0;34m(self, query, params, database, custom_error)\u001B[0m\n\u001B[1;32m     59\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_driver_exception(session, e)\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 61\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m     63\u001B[0m \u001B[38;5;66;03m# Though pandas support may be experimental in the `neo4j` package, it should always\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;66;03m# be supported in the `graphdatascience` package.\u001B[39;00m\n\u001B[1;32m     65\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     67\u001B[0m     message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m^pandas support is experimental and might be changed or removed in future versions$\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     68\u001B[0m )\n",
      "File \u001B[0;32m~/work/src-olga-fork/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:56\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.run_query\u001B[0;34m(self, query, params, database, custom_error)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_driver\u001B[38;5;241m.\u001B[39msession(database\u001B[38;5;241m=\u001B[39mdatabase, bookmarks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbookmarks()) \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 56\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     58\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m custom_error:\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/work/session.py:314\u001B[0m, in \u001B[0;36mSession.run\u001B[0;34m(self, query, parameters, **kwargs)\u001B[0m\n\u001B[1;32m    312\u001B[0m bookmarks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_bookmarks()\n\u001B[1;32m    313\u001B[0m parameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(parameters \u001B[38;5;129;01mor\u001B[39;00m {}, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 314\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_auto_result\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdatabase\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimpersonated_user\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdefault_access_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbookmarks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnotifications_min_severity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnotifications_disabled_categories\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_auto_result\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/work/result.py:166\u001B[0m, in \u001B[0;36mResult._run\u001B[0;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_categories)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pull()\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\u001B[38;5;241m.\u001B[39msend_all()\n\u001B[0;32m--> 166\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_attach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/work/result.py:274\u001B[0m, in \u001B[0;36mResult._attach\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exhausted \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_attached \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m--> 274\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:180\u001B[0m, in \u001B[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 180\u001B[0m         \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    181\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    182\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39miscoroutinefunction(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__on_error)\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/io/_bolt.py:851\u001B[0m, in \u001B[0;36mBolt.fetch_message\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    847\u001B[0m \u001B[38;5;66;03m# Receive exactly one message\u001B[39;00m\n\u001B[1;32m    848\u001B[0m tag, fields \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minbox\u001B[38;5;241m.\u001B[39mpop(\n\u001B[1;32m    849\u001B[0m     hydration_hooks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresponses[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mhydration_hooks\n\u001B[1;32m    850\u001B[0m )\n\u001B[0;32m--> 851\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtag\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfields\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39midle_since \u001B[38;5;241m=\u001B[39m perf_counter()\n\u001B[1;32m    853\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/io/_bolt5.py:376\u001B[0m, in \u001B[0;36mBolt5x0._process_message\u001B[0;34m(self, tag, fields)\u001B[0m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_server_state_manager\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbolt_states\u001B[38;5;241m.\u001B[39mFAILED\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 376\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_failure\u001B[49m\u001B[43m(\u001B[49m\u001B[43msummary_metadata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001B[1;32m    378\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool:\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:247\u001B[0m, in \u001B[0;36mResponse.on_failure\u001B[0;34m(self, metadata)\u001B[0m\n\u001B[1;32m    245\u001B[0m handler \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandlers\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_summary\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    246\u001B[0m Util\u001B[38;5;241m.\u001B[39mcallback(handler)\n\u001B[0;32m--> 247\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m Neo4jError\u001B[38;5;241m.\u001B[39mhydrate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmetadata)\n",
      "\u001B[0;31mClientError\u001B[0m: {code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=4, name='entity_id', type='UNIQUENESS', schema=(:Entity {id}), ownedIndex=3 )'.}"
     ]
    }
   ],
   "source": [
    "gds.run_cypher(\"CREATE CONSTRAINT entity_id FOR (e:Entity) REQUIRE e.id IS UNIQUE\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "rel_id_to_text_dict = {}\n",
    "for k in rel_dict:\n",
    "    text = k\n",
    "    id = rel_dict[k]\n",
    "    rel_id_to_text_dict[id] = text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(edge_index=[2, 272115], edge_type=[272115], num_nodes=14541), Data(edge_index=[2, 17535], edge_type=[17535], num_nodes=14541), Data(edge_index=[2, 20466], edge_type=[20466], num_nodes=14541)]\n",
      "2\n",
      "tensor([  0,   1,   2,  ..., 170,  30,  38])\n"
     ]
    }
   ],
   "source": [
    "print(data_list)\n",
    "print(data_list[0].edge_index[0][1].item())\n",
    "print(data_list[0].edge_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 541 elements...\n",
      "TOTAL records: 14541 from 14541\n"
     ]
    }
   ],
   "source": [
    "def write_chunk(chunk_dict):\n",
    "    gds.run_cypher(\n",
    "            \"UNWIND $nodes AS node CREATE (n:Entity {id: node[1], value: node[0]})\",\n",
    "            params={\"nodes\": list(chunk_dict.items())},\n",
    "        )\n",
    "    print(f\"Written {len(chunk_dict)} elements...\")\n",
    "\n",
    "idx = 0\n",
    "chunk_size = 1000\n",
    "chunk_dict = {}\n",
    "for k in node_dict:\n",
    "    chunk_dict[k] = node_dict[k]\n",
    "    idx += 1\n",
    "    if idx % chunk_size == 0:\n",
    "        write_chunk(chunk_dict)\n",
    "        chunk_dict = {}\n",
    "if len(chunk_dict) > 0:\n",
    "    write_chunk(chunk_dict)\n",
    "print(f\"TOTAL records: {idx} from {len(node_dict)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "train_data = data_list[0]\n",
    "val_data = data_list[1]\n",
    "test_data = data_list[2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing :TEST relationships\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 466 elements...\n",
      "TOTAL records: 20466 from 20466\n",
      "Writing :VAL relationships\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 535 elements...\n",
      "TOTAL records: 17535 from 17535\n",
      "Writing :TRAIN relationships\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 115 elements...\n",
      "TOTAL records: 272115 from 272115\n"
     ]
    }
   ],
   "source": [
    "def write_rel_chunk(ll:list, label):\n",
    "    gds.run_cypher(\n",
    "            \"UNWIND $list AS l MATCH (e_s:Entity {id: l[0]}), (e_t:Entity {id: l[1]}) \"+\n",
    "            \"CREATE (e_s)-[\"+label+\" { rel_id: l[2], text: l[3] }]->(e_t)\",\n",
    "            params={\"list\": ll},\n",
    "        )\n",
    "    print(f\"Written {len(ll)} elements...\")\n",
    "\n",
    "\n",
    "def create_rels(data:Data, label:str):\n",
    "    idx = 0\n",
    "    chunk_size = 1000\n",
    "    chunk_list = []\n",
    "    print(\"Writing \" + label + \" relationships\")\n",
    "    for i in range(data.num_edges):\n",
    "        source = data.edge_index[0, i].item()\n",
    "        target = data.edge_index[1, i].item()\n",
    "        id = data.edge_type[i].item()\n",
    "        text = rel_id_to_text_dict[id]\n",
    "        l = [source, target, id, text]\n",
    "        chunk_list.append(l)\n",
    "        idx += 1\n",
    "        if idx % chunk_size == 0:\n",
    "            write_rel_chunk(chunk_list, label)\n",
    "            chunk_list = []\n",
    "    if len(chunk_list) > 0:\n",
    "        write_rel_chunk(chunk_list, label)\n",
    "    print(f\"TOTAL records: {idx} from {data.num_edges}\")\n",
    "\n",
    "create_rels(test_data, \":TEST\")\n",
    "create_rels(val_data, \":VAL\")\n",
    "create_rels(train_data, \":TRAIN\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

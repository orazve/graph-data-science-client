{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience\n",
    "from torch_geometric.data import Data, download_url\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "gds = GraphDataScience(\"bolt://localhost:7687\", auth=('neo4j', 'neo4jneo4j'), database=\"fb15k-237\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing file train.txt\n",
      "Using existing file valid.txt\n",
      "Using existing file test.txt\n"
     ]
    }
   ],
   "source": [
    "url = ('https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/FB15k-237')\n",
    "raw_file_names = ['train.txt', 'valid.txt', 'test.txt']\n",
    "raw_dir = './data_from_url'\n",
    "for filename in raw_file_names:\n",
    "    download_url(f'{url}/{filename}', raw_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def process():\n",
    "    data_list_, node_dict_, rel_dict_ = [], {}, {}\n",
    "    for file_name in raw_file_names:\n",
    "        file_name_path = raw_dir + '/' + file_name\n",
    "        with open(file_name_path, 'r') as f:\n",
    "            data = [x.split('\\t') for x in f.read().split('\\n')[:-1]]\n",
    "\n",
    "        edge_index = torch.empty((2, len(data)), dtype=torch.long)\n",
    "        edge_type = torch.empty(len(data), dtype=torch.long)\n",
    "        for i, (src, rel, dst) in enumerate(data):\n",
    "            if src not in node_dict_:\n",
    "                node_dict_[src] = len(node_dict_)\n",
    "            if dst not in node_dict_:\n",
    "                node_dict_[dst] = len(node_dict_)\n",
    "            if rel not in rel_dict_:\n",
    "                rel_dict_[rel] = len(rel_dict_)\n",
    "\n",
    "            edge_index[0, i] = node_dict_[src]\n",
    "            edge_index[1, i] = node_dict_[dst]\n",
    "            edge_type[i] = rel_dict_[rel]\n",
    "\n",
    "        data = Data(edge_index=edge_index, edge_type=edge_type)\n",
    "        data_list_.append(data)\n",
    "\n",
    "    for data in data_list_:\n",
    "        data.num_nodes = len(node_dict_)\n",
    "\n",
    "    return data_list_, node_dict_, rel_dict_\n",
    "\n",
    "data_list, node_dict, rel_dict = process()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=4, name='entity_id', type='UNIQUENESS', schema=(:Entity {id}), ownedIndex=3 )'.}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mClientError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mgds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_cypher\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCREATE CONSTRAINT entity_id FOR (e:Entity) REQUIRE e.id IS UNIQUE\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/src-olga-fork/graph-data-science-client/graphdatascience/graph_data_science.py:234\u001B[0m, in \u001B[0;36mGraphDataScience.run_cypher\u001B[0;34m(self, query, params, database)\u001B[0m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_query_runner, ArrowQueryRunner):\n\u001B[1;32m    232\u001B[0m     qr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_query_runner\u001B[38;5;241m.\u001B[39mfallback_query_runner()\n\u001B[0;32m--> 234\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mqr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatabase\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/src-olga-fork/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:61\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.run_query\u001B[0;34m(self, query, params, database, custom_error)\u001B[0m\n\u001B[1;32m     59\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_driver_exception(session, e)\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 61\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m     63\u001B[0m \u001B[38;5;66;03m# Though pandas support may be experimental in the `neo4j` package, it should always\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;66;03m# be supported in the `graphdatascience` package.\u001B[39;00m\n\u001B[1;32m     65\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     67\u001B[0m     message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m^pandas support is experimental and might be changed or removed in future versions$\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     68\u001B[0m )\n",
      "File \u001B[0;32m~/work/src-olga-fork/graph-data-science-client/graphdatascience/query_runner/neo4j_query_runner.py:56\u001B[0m, in \u001B[0;36mNeo4jQueryRunner.run_query\u001B[0;34m(self, query, params, database, custom_error)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_driver\u001B[38;5;241m.\u001B[39msession(database\u001B[38;5;241m=\u001B[39mdatabase, bookmarks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbookmarks()) \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 56\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     58\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m custom_error:\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/work/session.py:314\u001B[0m, in \u001B[0;36mSession.run\u001B[0;34m(self, query, parameters, **kwargs)\u001B[0m\n\u001B[1;32m    312\u001B[0m bookmarks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_bookmarks()\n\u001B[1;32m    313\u001B[0m parameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(parameters \u001B[38;5;129;01mor\u001B[39;00m {}, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 314\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_auto_result\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdatabase\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimpersonated_user\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdefault_access_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbookmarks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnotifications_min_severity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnotifications_disabled_categories\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_auto_result\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/work/result.py:166\u001B[0m, in \u001B[0;36mResult._run\u001B[0;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_categories)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pull()\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\u001B[38;5;241m.\u001B[39msend_all()\n\u001B[0;32m--> 166\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_attach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/work/result.py:274\u001B[0m, in \u001B[0;36mResult._attach\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exhausted \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_attached \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m--> 274\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:180\u001B[0m, in \u001B[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 180\u001B[0m         \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    181\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    182\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m asyncio\u001B[38;5;241m.\u001B[39miscoroutinefunction(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__on_error)\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/io/_bolt.py:851\u001B[0m, in \u001B[0;36mBolt.fetch_message\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    847\u001B[0m \u001B[38;5;66;03m# Receive exactly one message\u001B[39;00m\n\u001B[1;32m    848\u001B[0m tag, fields \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minbox\u001B[38;5;241m.\u001B[39mpop(\n\u001B[1;32m    849\u001B[0m     hydration_hooks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresponses[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mhydration_hooks\n\u001B[1;32m    850\u001B[0m )\n\u001B[0;32m--> 851\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtag\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfields\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39midle_since \u001B[38;5;241m=\u001B[39m perf_counter()\n\u001B[1;32m    853\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/io/_bolt5.py:376\u001B[0m, in \u001B[0;36mBolt5x0._process_message\u001B[0;34m(self, tag, fields)\u001B[0m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_server_state_manager\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbolt_states\u001B[38;5;241m.\u001B[39mFAILED\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 376\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_failure\u001B[49m\u001B[43m(\u001B[49m\u001B[43msummary_metadata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001B[1;32m    378\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool:\n",
      "File \u001B[0;32m~/graph-data-science-client/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:247\u001B[0m, in \u001B[0;36mResponse.on_failure\u001B[0;34m(self, metadata)\u001B[0m\n\u001B[1;32m    245\u001B[0m handler \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandlers\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_summary\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    246\u001B[0m Util\u001B[38;5;241m.\u001B[39mcallback(handler)\n\u001B[0;32m--> 247\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m Neo4jError\u001B[38;5;241m.\u001B[39mhydrate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmetadata)\n",
      "\u001B[0;31mClientError\u001B[0m: {code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=4, name='entity_id', type='UNIQUENESS', schema=(:Entity {id}), ownedIndex=3 )'.}"
     ]
    }
   ],
   "source": [
    "gds.run_cypher(\"CREATE CONSTRAINT entity_id FOR (e:Entity) REQUIRE e.id IS UNIQUE\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "rel_id_to_text_dict = {}\n",
    "for k in rel_dict:\n",
    "    text = k\n",
    "    id = rel_dict[k]\n",
    "    rel_id_to_text_dict[id] = text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(edge_index=[2, 272115], edge_type=[272115], num_nodes=14541), Data(edge_index=[2, 17535], edge_type=[17535], num_nodes=14541), Data(edge_index=[2, 20466], edge_type=[20466], num_nodes=14541)]\n",
      "2\n",
      "tensor([  0,   1,   2,  ..., 170,  30,  38])\n"
     ]
    }
   ],
   "source": [
    "print(data_list)\n",
    "print(data_list[0].edge_index[0][1].item())\n",
    "print(data_list[0].edge_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 541 elements...\n",
      "TOTAL records: 14541 from 14541\n"
     ]
    }
   ],
   "source": [
    "def write_chunk(chunk_dict):\n",
    "    gds.run_cypher(\n",
    "            \"UNWIND $nodes AS node CREATE (n:Entity {id: node[1], value: node[0]})\",\n",
    "            params={\"nodes\": list(chunk_dict.items())},\n",
    "        )\n",
    "    print(f\"Written {len(chunk_dict)} elements...\")\n",
    "\n",
    "idx = 0\n",
    "chunk_size = 1000\n",
    "chunk_dict = {}\n",
    "for k in node_dict:\n",
    "    chunk_dict[k] = node_dict[k]\n",
    "    idx += 1\n",
    "    if idx % chunk_size == 0:\n",
    "        write_chunk(chunk_dict)\n",
    "        chunk_dict = {}\n",
    "if len(chunk_dict) > 0:\n",
    "    write_chunk(chunk_dict)\n",
    "print(f\"TOTAL records: {idx} from {len(node_dict)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_data = data_list[0]\n",
    "val_data = data_list[1]\n",
    "test_data = data_list[2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing :TEST relationships\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 466 elements...\n",
      "TOTAL records: 20466 from 20466\n",
      "Writing :VAL relationships\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 535 elements...\n",
      "TOTAL records: 17535 from 17535\n",
      "Writing :TRAIN relationships\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 1000 elements...\n",
      "Written 115 elements...\n",
      "TOTAL records: 272115 from 272115\n"
     ]
    }
   ],
   "source": [
    "def write_rel_chunk(ll:list, label):\n",
    "    gds.run_cypher(\n",
    "            \"UNWIND $list AS l MATCH (e_s:Entity {id: l[0]}), (e_t:Entity {id: l[1]}) \"+\n",
    "            \"CREATE (e_s)-[\"+label+\" { rel_id: l[2], text: l[3] }]->(e_t)\",\n",
    "            params={\"list\": ll},\n",
    "        )\n",
    "    print(f\"Written {len(ll)} elements...\")\n",
    "\n",
    "\n",
    "def create_rels(data:Data, label:str):\n",
    "    idx = 0\n",
    "    chunk_size = 1000\n",
    "    chunk_list = []\n",
    "    print(\"Writing \" + label + \" relationships\")\n",
    "    for i in range(data.num_edges):\n",
    "        source = data.edge_index[0, i].item()\n",
    "        target = data.edge_index[1, i].item()\n",
    "        id = data.edge_type[i].item()\n",
    "        text = rel_id_to_text_dict[id]\n",
    "        l = [source, target, id, text]\n",
    "        chunk_list.append(l)\n",
    "        idx += 1\n",
    "        if idx % chunk_size == 0:\n",
    "            write_rel_chunk(chunk_list, label)\n",
    "            chunk_list = []\n",
    "    if len(chunk_list) > 0:\n",
    "        write_rel_chunk(chunk_list, label)\n",
    "    print(f\"TOTAL records: {idx} from {data.num_edges}\")\n",
    "\n",
    "create_rels(test_data, \":TEST\")\n",
    "create_rels(val_data, \":VAL\")\n",
    "create_rels(train_data, \":TRAIN\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Node: (:Entity {id:int, value:str})\n",
    "# Edge: [:(TRAIN|TEST|VAL) {rel_id:int, text:str}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def get_data_from_db(edge_label):\n",
    "    node_projection = {\"Entity\": {\"properties\": \"id\"}}\n",
    "    relationship_projection = {edge_label : {\"orientation\": \"NATURAL\", \"properties\": \"rel_id\"}}\n",
    "    G, result = gds.graph.project(\n",
    "        \"fb15k-graph-t\"+edge_label,\n",
    "        node_projection,\n",
    "        relationship_projection,\n",
    "    )\n",
    "    print(f\"The projection took {result['projectMillis']} ms\")\n",
    "\n",
    "    # We can use convenience methods on `G` to check if the projection looks correct\n",
    "    print(f\"Graph '{G.name()}' node count: {G.node_count()}\")\n",
    "    print(f\"Graph '{G.name()}' node labels: {G.node_labels()}\")\n",
    "    print(f\"Graph '{G.name()}' relationship count: {G.relationship_count()}\")\n",
    "\n",
    "    return G\n",
    "\n",
    "def get_whole_dataset():\n",
    "    node_projection = {\"Entity\": {\"properties\": \"id\"}}\n",
    "    relationship_projection = {\n",
    "        \"TRAIN\" : {\"orientation\": \"NATURAL\", \"properties\": \"rel_id\"},\n",
    "        \"TEST\" : {\"orientation\": \"NATURAL\", \"properties\": \"rel_id\"},\n",
    "        \"VAL\" : {\"orientation\": \"NATURAL\", \"properties\": \"rel_id\"},\n",
    "    }\n",
    "    G, result = gds.graph.project(\n",
    "        \"fb15k-graph-whole\",\n",
    "        node_projection,\n",
    "        relationship_projection,\n",
    "    )\n",
    "    print(f\"The projection took {result['projectMillis']} ms\")\n",
    "\n",
    "    # We can use convenience methods on `G` to check if the projection looks correct\n",
    "    print(f\"Graph '{G.name()}' node count: {G.node_count()}\")\n",
    "    print(f\"Graph '{G.name()}' node labels: {G.node_labels()}\")\n",
    "    print(f\"Graph '{G.name()}' relationship count: {G.relationship_count()}\")\n",
    "\n",
    "    return G"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The projection took 47 ms\n",
      "Graph 'fb15k-graph-tTRAIN' node count: 14541\n",
      "Graph 'fb15k-graph-tTRAIN' node labels: ['Entity']\n",
      "Graph 'fb15k-graph-tTRAIN' relationship count: 272115\n",
      "The projection took 9 ms\n",
      "Graph 'fb15k-graph-tTEST' node count: 14541\n",
      "Graph 'fb15k-graph-tTEST' node labels: ['Entity']\n",
      "Graph 'fb15k-graph-tTEST' relationship count: 20466\n",
      "The projection took 22 ms\n",
      "Graph 'fb15k-graph-tVAL' node count: 14541\n",
      "Graph 'fb15k-graph-tVAL' node labels: ['Entity']\n",
      "Graph 'fb15k-graph-tVAL' relationship count: 17535\n",
      "The projection took 51 ms\n",
      "Graph 'fb15k-graph-whole' node count: 14541\n",
      "Graph 'fb15k-graph-whole' node labels: ['Entity']\n",
      "Graph 'fb15k-graph-whole' relationship count: 310116\n"
     ]
    }
   ],
   "source": [
    "train_db_data_G = get_data_from_db(\"TRAIN\")\n",
    "test_db_data_G = get_data_from_db(\"TEST\")\n",
    "val_db_data_G = get_data_from_db(\"VAL\")\n",
    "db_data_G = get_whole_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# gds.graph.drop(train_db_data_G)\n",
    "# gds.graph.drop(test_db_data_G)\n",
    "# gds.graph.drop(val_db_data_G)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(name=fb15k-graph-whole, node_count=14541, relationship_count=310116)\n"
     ]
    }
   ],
   "source": [
    "print(db_data_G)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       nodeId    id\n",
      "0       10000  9695\n",
      "1       10001  9696\n",
      "2       10002  9697\n",
      "3       10003  9698\n",
      "4       10004  9699\n",
      "...       ...   ...\n",
      "14536    9995  9690\n",
      "14537    9996  9691\n",
      "14538    9997  9692\n",
      "14539    9998  9693\n",
      "14540    9999  9694\n",
      "\n",
      "[14541 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "node_properties = gds.graph.nodeProperties.stream(\n",
    "    db_data_G,\n",
    "    [\"id\"],\n",
    "    separate_property_columns=True,\n",
    ")\n",
    "print(node_properties)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "nodeId_to_id = dict(zip(node_properties.nodeId, node_properties.id))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "        sourceNodeId  targetNodeId relationshipType\n0                  0           811              VAL\n1                  0          2664              VAL\n2                  0          4671              VAL\n3                  0          9126              VAL\n4                  0             2            TRAIN\n...              ...           ...              ...\n310111          9999          3249            TRAIN\n310112          9999          5257            TRAIN\n310113          9999          6475            TRAIN\n310114          9999         11890            TRAIN\n310115          9999         11890            TRAIN\n\n[310116 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sourceNodeId</th>\n      <th>targetNodeId</th>\n      <th>relationshipType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>811</td>\n      <td>VAL</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2664</td>\n      <td>VAL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>4671</td>\n      <td>VAL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>9126</td>\n      <td>VAL</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2</td>\n      <td>TRAIN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>310111</th>\n      <td>9999</td>\n      <td>3249</td>\n      <td>TRAIN</td>\n    </tr>\n    <tr>\n      <th>310112</th>\n      <td>9999</td>\n      <td>5257</td>\n      <td>TRAIN</td>\n    </tr>\n    <tr>\n      <th>310113</th>\n      <td>9999</td>\n      <td>6475</td>\n      <td>TRAIN</td>\n    </tr>\n    <tr>\n      <th>310114</th>\n      <td>9999</td>\n      <td>11890</td>\n      <td>TRAIN</td>\n    </tr>\n    <tr>\n      <th>310115</th>\n      <td>9999</td>\n      <td>11890</td>\n      <td>TRAIN</td>\n    </tr>\n  </tbody>\n</table>\n<p>310116 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_topology_df = gds.beta.graph.relationships.stream(db_data_G)\n",
    "# Let's see what we got:\n",
    "display(sample_topology_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "        sourceNodeId  targetNodeId relationshipType  rel_id\n0                  0           811              VAL   118.0\n1                  0          2664              VAL   195.0\n2                  0          4671              VAL     0.0\n3                  0          9126              VAL    23.0\n4                  0             2            TRAIN     0.0\n...              ...           ...              ...     ...\n310111          9999          3249            TRAIN    15.0\n310112          9999          5257            TRAIN   154.0\n310113          9999          6475            TRAIN    94.0\n310114          9999         11890            TRAIN    62.0\n310115          9999         11890            TRAIN   127.0\n\n[310116 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sourceNodeId</th>\n      <th>targetNodeId</th>\n      <th>relationshipType</th>\n      <th>rel_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>811</td>\n      <td>VAL</td>\n      <td>118.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2664</td>\n      <td>VAL</td>\n      <td>195.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>4671</td>\n      <td>VAL</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>9126</td>\n      <td>VAL</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2</td>\n      <td>TRAIN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>310111</th>\n      <td>9999</td>\n      <td>3249</td>\n      <td>TRAIN</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>310112</th>\n      <td>9999</td>\n      <td>5257</td>\n      <td>TRAIN</td>\n      <td>154.0</td>\n    </tr>\n    <tr>\n      <th>310113</th>\n      <td>9999</td>\n      <td>6475</td>\n      <td>TRAIN</td>\n      <td>94.0</td>\n    </tr>\n    <tr>\n      <th>310114</th>\n      <td>9999</td>\n      <td>11890</td>\n      <td>TRAIN</td>\n      <td>62.0</td>\n    </tr>\n    <tr>\n      <th>310115</th>\n      <td>9999</td>\n      <td>11890</td>\n      <td>TRAIN</td>\n      <td>127.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>310116 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m display(rels_tmp)\n\u001B[1;32m      3\u001B[0m rels_tmp\u001B[38;5;241m.\u001B[39mrel_id\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m \u001B[43mdisplay\u001B[49m(rels_tmp\u001B[38;5;241m.\u001B[39msourceNodeId\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x: nodeId_to_id[x]))\n",
      "Cell \u001B[0;32mIn[28], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m display(rels_tmp)\n\u001B[1;32m      3\u001B[0m rels_tmp\u001B[38;5;241m.\u001B[39mrel_id\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m \u001B[43mdisplay\u001B[49m(rels_tmp\u001B[38;5;241m.\u001B[39msourceNodeId\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x: nodeId_to_id[x]))\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "rels_tmp = gds.graph.relationshipProperties.stream(db_data_G, [\"rel_id\"], separate_property_columns=True)\n",
    "display(rels_tmp)\n",
    "rels_tmp.rel_id.astype(int)\n",
    "display(rels_tmp.sourceNodeId.map(lambda x: nodeId_to_id[x]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[    0,     0,     0,  ...,  9694,  9694,  9694],\n        [  774,  2550,  4494,  ...,  6225, 11585, 11585]])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor([118, 195,   0,  ...,  94,  62, 127])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 310116], edge_type=[310116], num_nodes=14541)\n"
     ]
    }
   ],
   "source": [
    "topology = [rels_tmp.sourceNodeId.map(lambda x: nodeId_to_id[x]), rels_tmp.targetNodeId.map(lambda x: nodeId_to_id[x])]\n",
    "edge_index = torch.tensor(topology, dtype=torch.long)\n",
    "edge_type = torch.tensor(rels_tmp.rel_id.astype(int), dtype=torch.long)\n",
    "display(edge_index)\n",
    "display(edge_type)\n",
    "data = Data(edge_index=edge_index, edge_type=edge_type)\n",
    "data.num_nodes = len(nodeId_to_id)\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(edge_index=[2, 272115], edge_type=[272115], num_nodes=14541)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Data(edge_index=[2, 20466], edge_type=[20466], num_nodes=14541)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Data(edge_index=[2, 17535], edge_type=[17535], num_nodes=14541)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_tensor(graph):\n",
    "    rels_tmp = gds.graph.relationshipProperties.stream(graph, [\"rel_id\"], separate_property_columns=True)\n",
    "    topology = [rels_tmp.sourceNodeId.map(lambda x: nodeId_to_id[x]), rels_tmp.targetNodeId.map(lambda x: nodeId_to_id[x])]\n",
    "    edge_index = torch.tensor(topology, dtype=torch.long)\n",
    "    edge_type = torch.tensor(rels_tmp.rel_id.astype(int), dtype=torch.long)\n",
    "    data = Data(edge_index=edge_index, edge_type=edge_type)\n",
    "    data.num_nodes = len(nodeId_to_id)\n",
    "    display(data)\n",
    "    return data\n",
    "\n",
    "train_tensor = create_tensor(train_db_data_G)\n",
    "test_tensor = create_tensor(test_db_data_G)\n",
    "val_tensor = create_tensor(val_db_data_G)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
